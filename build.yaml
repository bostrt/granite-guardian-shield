version: "2"
distribution_spec:
  description: Minimal Llama Stack build configuration for Granite Guardian and VLLM
  providers:
    inference:
    - remote::vllm
    - remote::ollama
    vector_io: []
    safety: []
    agents:
    - inline::meta-reference
    eval: []
    datasetio: []
    scoring: []
    telemetry:
    - inline::meta-reference
    tool_runtime: []
image_name: ls-granite-gaurdian
image_type: venv
additional_pip_packages:
- blobfile
- mcp
- aiosqlite
- sqlalchemy[asyncio] 
- opentelemetry-api
- opentelemetry-sdk
